
import string
import pandas as pd
import unicodedata
import re
!pip install Levenshtein
import Levenshtein
from joblib import Parallel, delayed
import time
from nltk.util import ngrams
from nltk.metrics import jaccard_distance
from collections import defaultdict


def remove_accents(input_str):
  nfkd_form = unicodedata.normalize('NFD', input_str)
  return ''.join([c for c in nfkd_form if not unicodedata.combining(c)])


def cleantext(text):
  if type(text) == int or type(text) == float or pd.isnull(text):
    return ""
  text = text.lower()
  text = text.translate(str.maketrans('', '', string.punctuation))#removes all punctuation
  text = ' '.join(text.split())#removes extra/ unnecesary spaces
  text = remove_accents(text)
  text = re.sub(r'(.)\1+', r'\1', text)#removes repeated letters

  vowels = "aeiouyAEIOUY"
  text = ''.join(char for char in text if char not in vowels)#removes all vowels
  return text

def cleannum(num):
  if pd.isnull(num):
        return ""
  num = str(num)
  num = num.translate(str.maketrans('', '', string.punctuation))
  num = num.replace(" ", "")
  return num


def compnumcin(line1, line2):#100%
  total =0

  #cin test
  if(line1["CIN_BENEF"]=="" or line2["CIN_BENEF"]==""):
    total +=0
  elif line1["CIN_BENEF"] ==  line2["CIN_BENEF"] :
    total += 4
  elif Levenshtein.distance(line1["CIN_BENEF"], line2["CIN_BENEF"]) <=2: #typing error
    total += 2
  else:
    total += -3

  #TEL test
  if(line1["TEL_BENEF"]=="" or  line2["TEL_BENEF"]==""):
    total +=0
  elif line1["TEL_BENEF"] ==  line2["TEL_BENEF"] :
    total += 3
  elif Levenshtein.distance(line1["TEL_BENEF"], line2["TEL_BENEF"]) <=2: #typing error
    total += 2
  else:
    total += -3

  if total ==7:
    total = 10 #both are exactly the same thus 100% match Bonus

  return total

def compfnamelname(line1, line2):#60%
  total =0
  #fname test
  if(line1["PREN_BENEF"]=="" or line2["PREN_BENEF"]==""):
    total +=0
  elif line1["PREN_BENEF"] ==  line2["PREN_BENEF"] :
    total += 2
  elif Levenshtein.distance(line1["PREN_BENEF"], line2["PREN_BENEF"]) <=2: #typing error
    total += 1
  else:
    total += -2


  #lname test
  if(line1["NOM_PREN_BENEF"]=="" or line2["NOM_PREN_BENEF"]==""):
    total +=0
  elif line1["NOM_PREN_BENEF"] ==  line2["NOM_PREN_BENEF"] :
    total += 2
  elif Levenshtein.distance(line1["NOM_PREN_BENEF"], line2["NOM_PREN_BENEF"]) <=2: #typing error
    total += 1
  else:
    total += -2

  if total == 4:
    total = 5 #likely match bonus
  return total


def compmomdad(line1, line2):#siblings
  total =0
  #mom name test
  if(line1["PREN_PERE_BENEF"]=="" or line2["PREN_PERE_BENEF"]==""):
    total +=0
  elif line1["PREN_PERE_BENEF"] ==  line2["PREN_PERE_BENEF"] :
    total += 2
  elif Levenshtein.distance(line1["PREN_PERE_BENEF"], line2["PREN_PERE_BENEF"]) <=2: #typing error
    total += 1
  else:
    total += -2


  #dad name test
  if(line1["PREN_MERE_BENEF"]=="" or line2["PREN_MERE_BENEF"]==""):
    total +=0
  elif line1["PREN_MERE_BENEF"] ==  line2["PREN_MERE_BENEF"] :
    total += 2
  elif Levenshtein.distance(line1["PREN_MERE_BENEF"], line2["PREN_MERE_BENEF"]) <=2: #typing error
    total += 1
  else:
    total += -2

  return total

def compaddress(line1, line2):#family
  total =0

  if line1["ADR_BENEF"] == "" or line2["ADR_BENEF"] == "":
    dist = 1.0
  else:
    set1 = set(line1["ADR_BENEF"].split())
    set2 = set(line2["ADR_BENEF"].split())
    dist = jaccard_distance(set1, set2) #?????? compares words rather than letters???? I thought because roads are agreed apon

  if dist <= 0.3:
    total += 2
  elif dist < 0.5:
    total += 1
  else :
    total += -1




  if line1["SEXE_BENEF"]== line2["SEXE_BENEF"] and line1["DATE_NAI_BENEF"] == line2["DATE_NAI_BENEF"]: #can be made better
    total += 1

  return total

# Main comparison function
def compare_pair(i, j):
    row_i = row_dicts[i]
    row_j = row_dicts[j]
    score = 0

    score += compfnamelname(row_i, row_j)
    score += compnumcin(row_i, row_j)

    if score <= 0:
        return None  # Skip weak matches early

    score += compmomdad(row_i, row_j)
    score += compaddress(row_i, row_j)

    if score > 7:
        return f"very likely match to {i + 2} : {j + 2} : {list(df.iloc[j])} Total: {score}"
    elif score > 5:
        return f"possible match to {i + 2} : {j + 2} : {list(df.iloc[j])} Total: {score}"
    else:
        return None











start = time.time()
#test
df_preview = pd.read_csv("/content/patient(1).csv",sep=";", nrows=1, encoding="cp1256")
print(df_preview.columns.tolist())


# Load
df = pd.read_csv(
    "/content/patient(1).csv",
    sep=";",
    encoding="cp1256",
    nrows=60000,
    usecols=[
        "NOM_PREN_BENEF", "DATE_NAI_BENEF", "SEXE_BENEF",
        "ADR_BENEF", "CIN_BENEF", "TEL_BENEF",
        "PREN_PERE_BENEF", "PREN_MERE_BENEF", "PREN_BENEF"
    ]

)

#clean
df.columns = [col.strip().replace('"', '') for col in df.columns]
rows =  list(df.itertuples(index=False))
df.columns = [col.strip().replace('"', '') for col in df.columns]

for i, row in enumerate(df.itertuples(index=False)):
    df.at[i, "NOM_PREN_BENEF"] = cleantext(row.NOM_PREN_BENEF)
    df.at[i, "ADR_BENEF"] = cleantext(row.ADR_BENEF)
    df.at[i, "PREN_PERE_BENEF"] = cleantext(row.PREN_PERE_BENEF)
    df.at[i, "PREN_MERE_BENEF"] = cleantext(row.PREN_MERE_BENEF)
    df.at[i, "PREN_BENEF"] = cleantext(row.PREN_BENEF)
    df.at[i, "SEXE_BENEF"] = cleantext(row.SEXE_BENEF)

    df.at[i, "CIN_BENEF"] = cleannum(row.CIN_BENEF)
    df.at[i, "TEL_BENEF"] = cleannum(row.TEL_BENEF)
    df.at[i, "DATE_NAI_BENEF"] = cleannum(row.DATE_NAI_BENEF)

rows =  list(df.itertuples(index=False))

row_dicts = [row._asdict() for row in rows]#dictionary conversion
blocks = defaultdict(list)
for idx, row in enumerate(row_dicts):
    lname = row["NOM_PREN_BENEF"]
    if lname:
        key = lname[0]  # First letter
    else:
        key = "#"  # default group for empty last names
    blocks[key].append((idx, row))

# Parallel pairwise comparisons within blocks
results = []
for block_key, entries in blocks.items():
    indices = [idx for idx, _ in entries]
    block_results = Parallel(n_jobs=-1, backend="loky", verbose=10)(
        delayed(compare_pair)(i, j)
        for idx_i, i in enumerate(indices)
        for j in indices[idx_i + 1:]
    )
    results.extend(block_results)

# Print matches
for result in results:
    if result:
        print(result)

print("Finished in", time.time() - start, "seconds") 
